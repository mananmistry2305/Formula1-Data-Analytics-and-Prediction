{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mistr\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from io import StringIO\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "constructor_results = pd.read_csv('constructor_results.csv')\n",
    "constructor_standings = pd.read_csv('constructor_standings.csv')\n",
    "constructors = pd.read_csv('constructors.csv')\n",
    "driver_standings = pd.read_csv('driver_standings.csv')\n",
    "drivers = pd.read_csv('drivers.csv')\n",
    "lap_times = pd.read_csv('lap_times.csv')\n",
    "pit_stops = pd.read_csv('pit_stops.csv')\n",
    "qualifying = pd.read_csv('qualifying.csv')\n",
    "races = pd.read_csv('races.csv')\n",
    "results = pd.read_csv('results.csv')\n",
    "circuits = pd.read_csv('circuits.csv')\n",
    "seasons = pd.read_csv('seasons.csv')\n",
    "sprint_results = pd.read_csv('sprint_results.csv')\n",
    "status = pd.read_csv('status.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged Data Sample:\n",
      "   resultId  raceId  driverId  constructorId number  grid position_driver  \\\n",
      "0         1      18         1              1     22     1               1   \n",
      "1         2      18         2              2      3     5               2   \n",
      "2         3      18         3              3      7     7               3   \n",
      "3         4      18         4              4      5    11               4   \n",
      "4         5      18         5              1     23     3               5   \n",
      "\n",
      "  positionText  positionOrder  points_driver  ...  name_x               Name  \\\n",
      "0            1              1           10.0  ...     NaN     Lewis Hamilton   \n",
      "1            2              2            8.0  ...     NaN      Nick Heidfeld   \n",
      "2            3              3            6.0  ...     NaN       Nico Rosberg   \n",
      "3            4              4            5.0  ...     NaN    Fernando Alonso   \n",
      "4            5              5            4.0  ...     NaN  Heikki Kovalainen   \n",
      "\n",
      "  code      name_y points_standings position_standings points  position  \\\n",
      "0  HAM     McLaren             10.0                1.0   14.0       1.0   \n",
      "1  HEI  BMW Sauber              8.0                2.0    8.0       3.0   \n",
      "2  ROS    Williams              6.0                3.0    9.0       2.0   \n",
      "3  ALO     Renault              5.0                4.0    5.0       4.0   \n",
      "4  KOV     McLaren              4.0                5.0   14.0       1.0   \n",
      "\n",
      "   position_qualifying  podium  \n",
      "0                  1.0       1  \n",
      "1                  5.0       1  \n",
      "2                  7.0       1  \n",
      "3                 12.0       0  \n",
      "4                  3.0       0  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Filter to last 10 years\n",
    "recent_races = races[races['year'] >= (races['year'].max() - 10)]\n",
    "\n",
    "# Step 2: Merge datasets - adjusting for the presence of 'raceId' in each dataset\n",
    "merged_data = results.copy()\n",
    "\n",
    "# Merge with recent races (this includes 'raceId' and 'circuitId')\n",
    "if 'raceId' in recent_races.columns:\n",
    "    merged_data = merged_data.merge(recent_races[['raceId', 'year', 'circuitId']], on='raceId', how='left')\n",
    "\n",
    "# Merge with circuits dataset\n",
    "if 'circuitId' in circuits.columns:\n",
    "    merged_data = merged_data.merge(circuits[['circuitId', 'name']], on='circuitId', how='left')\n",
    "\n",
    "# Merge with drivers dataset (assuming driverId is in both)\n",
    "if 'driverId' in drivers.columns:\n",
    "    merged_data = merged_data.merge(drivers[['driverId', 'Name', 'code']], on='driverId', how='left')\n",
    "\n",
    "# Merge with constructors dataset (assuming constructorId is in both)\n",
    "if 'constructorId' in constructors.columns:\n",
    "    merged_data = merged_data.merge(constructors[['constructorId', 'name']], on='constructorId', how='left')\n",
    "\n",
    "# Merge with driver_standings dataset\n",
    "if {'driverId', 'raceId'}.issubset(driver_standings.columns):\n",
    "    merged_data = merged_data.merge(driver_standings[['driverId', 'raceId', 'points', 'position']], \n",
    "                                    on=['driverId', 'raceId'], \n",
    "                                    how='left', suffixes=('_driver', '_standings'))\n",
    "\n",
    "# Merge with constructor_standings dataset\n",
    "if {'constructorId', 'raceId'}.issubset(constructor_standings.columns):\n",
    "    merged_data = merged_data.merge(constructor_standings[['constructorId', 'raceId', 'points', 'position']], \n",
    "                                    on=['constructorId', 'raceId'], \n",
    "                                    how='left', suffixes=('_constructor', '_constructor_standings'))\n",
    "\n",
    "# Merge with qualifying dataset\n",
    "if {'raceId', 'driverId'}.issubset(qualifying.columns):\n",
    "    merged_data = merged_data.merge(qualifying[['raceId', 'driverId', 'position']], \n",
    "                                    on=['raceId', 'driverId'], \n",
    "                                    how='left', suffixes=('', '_qualifying'))\n",
    "\n",
    "# Step 3: Add target variable (podium: 1 if positionOrder <= 3, else 0)\n",
    "merged_data['podium'] = (merged_data['positionOrder'] <= 3).astype(int)\n",
    "\n",
    "merged_data.to_excel(\"merged_data.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names in merged_data:\n",
      "['resultId', 'raceId', 'driverId', 'constructorId', 'number', 'grid', 'position_driver', 'positionText', 'positionOrder', 'points_driver', 'laps', 'time', 'milliseconds', 'fastestLap', 'rank', 'fastestLapTime', 'fastestLapSpeed', 'statusId', 'year', 'circuitId', 'name_x', 'Name', 'code', 'name_y', 'points_standings', 'position_standings', 'points', 'position', 'position_qualifying', 'podium']\n"
     ]
    }
   ],
   "source": [
    "# Display all column names in the merged_data DataFrame\n",
    "print(\"Column names in merged_data:\")\n",
    "print(merged_data.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      constructorId  raceId  constructor_experience\n",
      "7571              1       1                       1\n",
      "7572              1       1                       2\n",
      "7579              1       2                       3\n",
      "7592              1       2                       4\n",
      "7597              1       3                       5\n",
      "7598              1       3                       6\n",
      "7616              1       4                       7\n",
      "7624              1       4                       8\n",
      "7641              1       5                       9\n",
      "7648              1       5                      10\n"
     ]
    }
   ],
   "source": [
    "# Constructor Experience (By races, +1 for each driver)\n",
    "\n",
    "# Step 1: Calculate the number of races each constructor has participated in\n",
    "# Sort by constructorId and raceId to ensure cumulative experience\n",
    "merged_data = merged_data.sort_values(by=['constructorId', 'raceId'])\n",
    "\n",
    "# Step 2: Create a constructor experience column, cumulative count of races for each constructor\n",
    "merged_data['constructor_experience'] = merged_data.groupby('constructorId').cumcount() + 1\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(merged_data[['constructorId', 'raceId', 'constructor_experience']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      driverId  raceId  driver_experience\n",
      "7572         1       1                  1\n",
      "7579         1       2                  2\n",
      "7598         1       3                  3\n",
      "7616         1       4                  4\n",
      "7641         1       5                  5\n",
      "7664         1       6                  6\n",
      "7685         1       7                  7\n",
      "7708         1       8                  8\n",
      "7730         1       9                  9\n",
      "7733         1      10                 10\n"
     ]
    }
   ],
   "source": [
    "# Driver Experience (By races, +1 for each race)\n",
    "\n",
    "# Step 1: Sort by driverId and raceId to ensure cumulative experience is calculated sequentially\n",
    "merged_data = merged_data.sort_values(by=['driverId', 'raceId'])\n",
    "\n",
    "# Step 2: Create a driver experience column, cumulative count of races for each driver\n",
    "merged_data['driver_experience'] = merged_data.groupby('driverId').cumcount() + 1\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(merged_data[['driverId', 'raceId', 'driver_experience']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   driverId  raceId        dob       date  driver_age\n",
      "0         1       1 1985-01-07 2009-03-29   24.221766\n",
      "1         1       2 1985-01-07 2009-04-05   24.240931\n",
      "2         1       3 1985-01-07 2009-04-19   24.279261\n",
      "3         1       4 1985-01-07 2009-04-26   24.298426\n",
      "4         1       5 1985-01-07 2009-05-10   24.336756\n",
      "5         1       6 1985-01-07 2009-05-24   24.375086\n",
      "6         1       7 1985-01-07 2009-06-07   24.413415\n",
      "7         1       8 1985-01-07 2009-06-21   24.451745\n",
      "8         1       9 1985-01-07 2009-07-12   24.509240\n",
      "9         1      10 1985-01-07 2009-07-26   24.547570\n"
     ]
    }
   ],
   "source": [
    "# Driver Age\n",
    "\n",
    "# Step 1: Ensure dob is in merged_data by merging with the drivers dataset if necessary\n",
    "if 'dob' not in merged_data.columns:\n",
    "    merged_data = merged_data.merge(drivers[['driverId', 'dob']], on='driverId', how='left')\n",
    "\n",
    "# Step 2: Ensure race date is in merged_data by merging with the races dataset if necessary\n",
    "if 'date' not in merged_data.columns:\n",
    "    merged_data = merged_data.merge(races[['raceId', 'date']], on='raceId', how='left')\n",
    "\n",
    "# Step 3: Convert 'dob' and 'date' to datetime format if they are not already\n",
    "merged_data['dob'] = pd.to_datetime(merged_data['dob'])\n",
    "merged_data['date'] = pd.to_datetime(merged_data['date'])\n",
    "\n",
    "# Step 4: Calculate driver age at the time of each race in years\n",
    "merged_data['driver_age'] = (merged_data['date'] - merged_data['dob']).dt.days / 365.25\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(merged_data[['driverId', 'raceId', 'dob', 'date', 'driver_age']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   driverId  raceId  positionOrder  driver_wins\n",
      "0         1       1             20            0\n",
      "1         1       2              7            0\n",
      "2         1       3              6            0\n",
      "3         1       4              4            0\n",
      "4         1       5              9            0\n",
      "5         1       6             12            0\n",
      "6         1       7             13            0\n",
      "7         1       8             16            0\n",
      "8         1       9             18            0\n",
      "9         1      10              1            1\n"
     ]
    }
   ],
   "source": [
    "# Driver Wins\n",
    "# Step 1: Create a binary column indicating if the driver won the race (positionOrder == 1)\n",
    "merged_data['win'] = (merged_data['positionOrder'] == 1).astype(int)\n",
    "\n",
    "# Step 2: Calculate cumulative wins for each driver\n",
    "merged_data = merged_data.sort_values(by=['driverId', 'raceId'])\n",
    "merged_data['driver_wins'] = merged_data.groupby('driverId')['win'].cumsum()\n",
    "\n",
    "# Drop the temporary 'win' column if you no longer need it\n",
    "merged_data.drop(columns='win', inplace=True)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(merged_data[['driverId', 'raceId', 'positionOrder', 'driver_wins']].head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      constructorId  raceId  positionOrder  constructor_wins\n",
      "0                 1       1             20                 0\n",
      "1126              1       1             19                 0\n",
      "1                 1       2              7                 0\n",
      "1127              1       2             20                 0\n",
      "2                 1       3              6                 0\n",
      "1128              1       3              5                 0\n",
      "3                 1       4              4                 0\n",
      "1129              1       4             12                 0\n",
      "4                 1       5              9                 0\n",
      "1130              1       5             16                 0\n"
     ]
    }
   ],
   "source": [
    "# Constructor Wins\n",
    "\n",
    "# Step 1: Create a binary column indicating if the constructor won the race (positionOrder == 1)\n",
    "merged_data['constructor_win'] = (merged_data['positionOrder'] == 1).astype(int)\n",
    "\n",
    "# Step 2: Calculate cumulative wins for each constructor\n",
    "merged_data = merged_data.sort_values(by=['constructorId', 'raceId'])\n",
    "merged_data['constructor_wins'] = merged_data.groupby('constructorId')['constructor_win'].cumsum()\n",
    "\n",
    "# Drop the temporary 'constructor_win' column if you no longer need it\n",
    "merged_data.drop(columns='constructor_win', inplace=True)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(merged_data[['constructorId', 'raceId', 'positionOrder', 'constructor_wins']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   driverId  constructorId  raceId  driver_exp_with_constructor\n",
      "0         1              1       1                            1\n",
      "1         1              1       2                            2\n",
      "2         1              1       3                            3\n",
      "3         1              1       4                            4\n",
      "4         1              1       5                            5\n",
      "5         1              1       6                            6\n",
      "6         1              1       7                            7\n",
      "7         1              1       8                            8\n",
      "8         1              1       9                            9\n",
      "9         1              1      10                           10\n"
     ]
    }
   ],
   "source": [
    "# Driver Exp with Constructor\n",
    "\n",
    "# Step 1: Sort by driverId, constructorId, and raceId to ensure sequential counting\n",
    "merged_data = merged_data.sort_values(by=['driverId', 'constructorId', 'raceId'])\n",
    "\n",
    "# Step 2: Calculate cumulative experience with each constructor for each driver\n",
    "merged_data['driver_exp_with_constructor'] = merged_data.groupby(['driverId', 'constructorId']).cumcount() + 1\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(merged_data[['driverId', 'constructorId', 'raceId', 'driver_exp_with_constructor']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resultId</th>\n",
       "      <th>raceId</th>\n",
       "      <th>driverId</th>\n",
       "      <th>constructorId</th>\n",
       "      <th>number</th>\n",
       "      <th>grid</th>\n",
       "      <th>position_driver</th>\n",
       "      <th>positionText</th>\n",
       "      <th>positionOrder</th>\n",
       "      <th>points_driver</th>\n",
       "      <th>...</th>\n",
       "      <th>position_qualifying</th>\n",
       "      <th>podium</th>\n",
       "      <th>constructor_experience</th>\n",
       "      <th>driver_experience</th>\n",
       "      <th>dob</th>\n",
       "      <th>date</th>\n",
       "      <th>driver_age</th>\n",
       "      <th>driver_wins</th>\n",
       "      <th>constructor_wins</th>\n",
       "      <th>driver_exp_with_constructor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7573</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>\\N</td>\n",
       "      <td>D</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1985-01-07</td>\n",
       "      <td>2009-03-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7580</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1985-01-07</td>\n",
       "      <td>2009-04-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7599</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1985-01-07</td>\n",
       "      <td>2009-04-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7617</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1985-01-07</td>\n",
       "      <td>2009-04-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7642</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1985-01-07</td>\n",
       "      <td>2009-05-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   resultId  raceId  driverId  constructorId number  grid position_driver  \\\n",
       "0      7573       1         1              1      1    18              \\N   \n",
       "1      7580       2         1              1      1    12               7   \n",
       "2      7599       3         1              1      1     9               6   \n",
       "3      7617       4         1              1      1     5               4   \n",
       "4      7642       5         1              1      1    14               9   \n",
       "\n",
       "  positionText  positionOrder  points_driver  ...  position_qualifying podium  \\\n",
       "0            D             20            0.0  ...                 15.0      0   \n",
       "1            7              7            1.0  ...                 13.0      0   \n",
       "2            6              6            3.0  ...                  9.0      0   \n",
       "3            4              4            5.0  ...                  5.0      0   \n",
       "4            9              9            0.0  ...                 14.0      0   \n",
       "\n",
       "  constructor_experience driver_experience        dob       date driver_age  \\\n",
       "0                      1                 1 1985-01-07 2009-03-29        NaN   \n",
       "1                      3                 2 1985-01-07 2009-04-05        NaN   \n",
       "2                      5                 3 1985-01-07 2009-04-19        NaN   \n",
       "3                      7                 4 1985-01-07 2009-04-26        NaN   \n",
       "4                      9                 5 1985-01-07 2009-05-10        NaN   \n",
       "\n",
       "   driver_wins  constructor_wins  driver_exp_with_constructor  \n",
       "0            0                 0                            1  \n",
       "1            0                 0                            2  \n",
       "2            0                 0                            3  \n",
       "3            0                 0                            4  \n",
       "4            0                 0                            5  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Constructor Experience\n",
    "# Sort by constructorId and raceId to ensure cumulative experience is calculated sequentially\n",
    "merged_data = merged_data.sort_values(by=['constructorId', 'raceId'])\n",
    "merged_data['constructor_experience'] = merged_data.groupby('constructorId').cumcount() + 1\n",
    "\n",
    "# Step 2: Driver Experience\n",
    "# Sort by driverId and raceId to ensure cumulative experience is calculated sequentially\n",
    "merged_data = merged_data.sort_values(by=['driverId', 'raceId'])\n",
    "merged_data['driver_experience'] = merged_data.groupby('driverId').cumcount() + 1\n",
    "\n",
    "# Step 3: Driver Age\n",
    "# Assuming `dob` is in the `drivers` dataset and `date` is in the `races` dataset, we merge these\n",
    "# if needed to calculate driver age at the time of each race\n",
    "# Convert date columns if needed\n",
    "if 'dob' in merged_data.columns and 'year' in merged_data.columns:\n",
    "    # Calculate age (approximate years)\n",
    "    merged_data['driver_age'] = (merged_data['year'] - pd.to_datetime(merged_data['dob']).dt.year)\n",
    "\n",
    "# Step 4: Driver Wins\n",
    "# Create a binary column indicating if the driver won the race (positionOrder == 1)\n",
    "merged_data['win'] = (merged_data['positionOrder'] == 1).astype(int)\n",
    "\n",
    "# Calculate cumulative wins for each driver\n",
    "merged_data['driver_wins'] = merged_data.groupby('driverId')['win'].cumsum()\n",
    "\n",
    "# Step 5: Constructor Wins\n",
    "# Create a binary column indicating if the constructor won the race (positionOrder == 1)\n",
    "merged_data['constructor_win'] = (merged_data['positionOrder'] == 1).astype(int)\n",
    "\n",
    "# Calculate cumulative wins for each constructor\n",
    "merged_data['constructor_wins'] = merged_data.groupby('constructorId')['constructor_win'].cumsum()\n",
    "\n",
    "# Step 6: Driver Experience with Constructor\n",
    "# Sort by driverId, constructorId, and raceId to ensure sequential counting\n",
    "merged_data = merged_data.sort_values(by=['driverId', 'constructorId', 'raceId'])\n",
    "merged_data['driver_exp_with_constructor'] = merged_data.groupby(['driverId', 'constructorId']).cumcount() + 1\n",
    "\n",
    "# Drop temporary columns used for wins\n",
    "merged_data.drop(columns=['win', 'constructor_win'], inplace=True)\n",
    "\n",
    "# Display the final table with all feature-engineered variables\n",
    "merged_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Performance:\n",
      "Accuracy: 0.9911387631975868\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      4650\n",
      "           1       0.96      0.97      0.96       654\n",
      "\n",
      "    accuracy                           0.99      5304\n",
      "   macro avg       0.98      0.98      0.98      5304\n",
      "weighted avg       0.99      0.99      0.99      5304\n",
      "\n",
      "\n",
      "SVC Performance:\n",
      "Accuracy: 0.9711538461538461\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      4650\n",
      "           1       0.90      0.86      0.88       654\n",
      "\n",
      "    accuracy                           0.97      5304\n",
      "   macro avg       0.94      0.92      0.93      5304\n",
      "weighted avg       0.97      0.97      0.97      5304\n",
      "\n",
      "\n",
      "Logistic Regression Performance:\n",
      "Accuracy: 0.9374057315233786\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96      4650\n",
      "           1       0.79      0.67      0.72       654\n",
      "\n",
      "    accuracy                           0.94      5304\n",
      "   macro avg       0.87      0.82      0.84      5304\n",
      "weighted avg       0.93      0.94      0.93      5304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Step 1: Define Features and Target Variable\n",
    "features = merged_data[['grid', 'points_driver', 'points_standings', 'constructor_experience', \n",
    "                        'driver_experience','driver_age', 'driver_wins', 'constructor_wins', \n",
    "                        'driver_exp_with_constructor']]\n",
    "target = merged_data['podium']\n",
    "\n",
    "# Step 2: Data Preprocessing\n",
    "# Replace non-numeric placeholders ('\\\\N') with NaN\n",
    "features = features.replace('\\\\N', np.nan)\n",
    "\n",
    "# Convert columns to numeric to ensure all are suitable for imputation\n",
    "features = features.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Handle missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "features_imputed = imputer.fit_transform(features)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features_imputed)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_scaled, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Model Training and Evaluation\n",
    "# Define the models\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'SVC': SVC(random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000)\n",
    "}\n",
    "\n",
    "# Train each model and evaluate performance\n",
    "for model_name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    print(f\"\\n{model_name} Performance:\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest:\n",
    "Accuracy: 99.1%\n",
    "High precision and recall for both classes, indicating it’s effective at identifying podium finishes with minimal misclassification.\n",
    "Strongest performance among the models, with balanced precision, recall, and F1-score.\n",
    "\n",
    "\n",
    "Support Vector Classifier (SVC):\n",
    "Accuracy: 97.1%\n",
    "High precision and recall for the non-podium class (0) but slightly lower recall for the podium class (1), which indicates some difficulty in detecting all podium instances.\n",
    "Still an effective model, but slightly less accurate than Random Forest, particularly in handling the minority class.\n",
    "\n",
    "\n",
    "Logistic Regression:\n",
    "Accuracy: 93.7%\n",
    "Lower recall for the podium class, indicating that it has more difficulty identifying podium finishes.\n",
    "This model is the least accurate overall, suggesting that the relationships in the data may be better captured by non-linear models like Random Forest and SVC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'merged_data' is preloaded with all required engineered features\n",
    "# Define the features and target\n",
    "features = merged_data[['driverId', 'grid', 'circuitId', 'constructor_experience', \n",
    "                        'driver_experience', 'driver_age', 'driver_wins', \n",
    "                        'constructor_wins', 'driver_exp_with_constructor']]\n",
    "target = merged_data['podium']\n",
    "\n",
    "# Step 1: Data Preprocessing\n",
    "# Handle missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "features_imputed = imputer.fit_transform(features)\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features_imputed)\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "rf_model.fit(features_scaled, target)\n",
    "\n",
    "# Step 2: Create Prediction Function\n",
    "def predict_podium(driver_name, grid_position, circuit_name):\n",
    "    # Find driverId based on driver name\n",
    "    driver_id = merged_data[merged_data['Name'] == driver_name]['driverId'].iloc[0]\n",
    "    \n",
    "    # Find circuitId based on circuit name\n",
    "    circuit_id = merged_data[merged_data['name_x'] == circuit_name]['circuitId'].iloc[0]\n",
    "    \n",
    "    # Retrieve the most recent constructor experience and driver experience with constructor values\n",
    "    latest_data = merged_data[(merged_data['driverId'] == driver_id) & (merged_data['circuitId'] == circuit_id)].iloc[-1]\n",
    "    \n",
    "    # Prepare the input data\n",
    "    input_data = pd.DataFrame({\n",
    "        'driverId': [driver_id],\n",
    "        'grid': [grid_position],\n",
    "        'circuitId': [circuit_id],\n",
    "        'constructor_experience': [latest_data['constructor_experience']],\n",
    "        'driver_experience': [latest_data['driver_experience']],\n",
    "        'driver_age': [latest_data['driver_age']],\n",
    "        'driver_wins': [latest_data['driver_wins']],\n",
    "        'constructor_wins': [latest_data['constructor_wins']],\n",
    "        'driver_exp_with_constructor': [latest_data['driver_exp_with_constructor']]\n",
    "    })\n",
    "\n",
    "    # Process input data (Imputation and Scaling)\n",
    "    input_data_imputed = imputer.transform(input_data)\n",
    "    input_data_scaled = scaler.transform(input_data_imputed)\n",
    "    \n",
    "    # Predict podium probability\n",
    "    podium_probability = rf_model.predict_proba(input_data_scaled)[0][1] * 100\n",
    "    \n",
    "    return f\"The probability of {driver_name} achieving a podium finish at {circuit_name} from grid position {grid_position} is {podium_probability:.2f}%.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of Charles Leclerc achieving a podium finish at Baku City Circuit from grid position 14 is 0.00%.\n"
     ]
    }
   ],
   "source": [
    "print(predict_podium(driver_name=\"Charles Leclerc\", grid_position=14, circuit_name=\"Baku City Circuit\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
